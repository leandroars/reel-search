{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4aUYU6/lSaVokfiJKW+nn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "931a6e42b8fa4e2da219fd6b21ee239f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_df5a52d5b2d94191af89f9473b457bd3"
          }
        },
        "504e953d0e894f6c8d32d9922fddc35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adfaabef2108452a86cc41ddb1a99ca4",
            "placeholder": "​",
            "style": "IPY_MODEL_fa0c97d8e3604fc8a7bb0617a9b51a2f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "23d16104aa7d42c3a160b40e1280a40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3b968a37ee214a778fb3e6163217e71b",
            "placeholder": "​",
            "style": "IPY_MODEL_42eda2525ba04635b0f07e3d5cac4ef6",
            "value": ""
          }
        },
        "7cc09649b5714ff9b91920bbcd516ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b4c41b70f95a463bbb92a0c4166bf3f9",
            "style": "IPY_MODEL_96134acd1a3440b2b0036e3f1f5937df",
            "value": true
          }
        },
        "74e32b5be94b42eb93dec65f46b3f223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_88f88e2458d14dfd85c7d6b37c48f3a9",
            "style": "IPY_MODEL_9d352c6094de4f379f5dec36b1c4d558",
            "tooltip": ""
          }
        },
        "26f52afe82bb49e9b0cabb34b4b82b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad3141501e654a0da477ffa807e1177f",
            "placeholder": "​",
            "style": "IPY_MODEL_962928cba68d4b7f900761b26c28b87f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "df5a52d5b2d94191af89f9473b457bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "adfaabef2108452a86cc41ddb1a99ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0c97d8e3604fc8a7bb0617a9b51a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b968a37ee214a778fb3e6163217e71b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42eda2525ba04635b0f07e3d5cac4ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c41b70f95a463bbb92a0c4166bf3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96134acd1a3440b2b0036e3f1f5937df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88f88e2458d14dfd85c7d6b37c48f3a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d352c6094de4f379f5dec36b1c4d558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ad3141501e654a0da477ffa807e1177f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962928cba68d4b7f900761b26c28b87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4bbb9443ae34cfe92ea18a733060aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df33fbc34a434dd2850060412ea47619",
            "placeholder": "​",
            "style": "IPY_MODEL_05658a550ad74430911194c2fce5e014",
            "value": "Connecting..."
          }
        },
        "df33fbc34a434dd2850060412ea47619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05658a550ad74430911194c2fce5e014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ec28634284f4ee8bf7656d4147e4c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_cb55e92abf98428d9c507d882d86d315"
          }
        },
        "4c7e99f63a1f4aa3b188a6275af0f59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c7963f5c4564a2cb4f26cfd47153264",
            "placeholder": "​",
            "style": "IPY_MODEL_c346740c970c47c5a81e02f233844750",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "a5c3338582554eba9bd804bde3276eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ab724bd14f16449eb15e6871332c7359",
            "placeholder": "​",
            "style": "IPY_MODEL_7f67494d579d43fc83eff7126e9290d8",
            "value": ""
          }
        },
        "79db8f1530be4f06a35f2af908ca5041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_596bb8785dce4bb8af148731d60c08f1",
            "style": "IPY_MODEL_350fea18778f40289288315a96717624",
            "value": true
          }
        },
        "2324aa3b022540caa54d924e700a536b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_660b7103569643dfab5f63f88e229b8f",
            "style": "IPY_MODEL_eda8a3845bb94d4ab7e067303d5fd5c6",
            "tooltip": ""
          }
        },
        "f5613da8560b4a6ab84e95cd6b12dd66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d758cee1b7e43a2a539a5aa9784cd51",
            "placeholder": "​",
            "style": "IPY_MODEL_a52b68e1a2f0481ba0eb15220de0d674",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "cb55e92abf98428d9c507d882d86d315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "4c7963f5c4564a2cb4f26cfd47153264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c346740c970c47c5a81e02f233844750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab724bd14f16449eb15e6871332c7359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f67494d579d43fc83eff7126e9290d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "596bb8785dce4bb8af148731d60c08f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "350fea18778f40289288315a96717624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "660b7103569643dfab5f63f88e229b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda8a3845bb94d4ab7e067303d5fd5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4d758cee1b7e43a2a539a5aa9784cd51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52b68e1a2f0481ba0eb15220de0d674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "551097d9381d4d7abc7d0a0c5bc7bdc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93480f0fefa34fd3ba00e5ddcea892b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5eff9558fcac4a7a9f056e46c6fad38f",
            "value": "Connecting..."
          }
        },
        "93480f0fefa34fd3ba00e5ddcea892b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eff9558fcac4a7a9f056e46c6fad38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leandroars/reel-search/blob/master/teste3d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlcGjb-x-AGo",
        "outputId": "2d544c3a-ea0a-4400-f548-06cbe4fcb600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 25 03:08:32 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Cloning into 'sam-3d-objects'...\n",
            "remote: Enumerating objects: 1101, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 1101 (delta 75), reused 64 (delta 64), pack-reused 1007 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1101/1101), 266.74 MiB | 35.72 MiB/s, done.\n",
            "Resolving deltas: 100% (401/401), done.\n",
            "/content/sam-3d-objects\n"
          ]
        }
      ],
      "source": [
        "# 1. Verificar qual GPU o Google te deu (esperamos uma Tesla T4 ou superior)\n",
        "!nvidia-smi\n",
        "\n",
        "# 2. Clonar o repositório oficial\n",
        "!git clone https://github.com/facebookresearch/sam-3d-objects.git\n",
        "\n",
        "# 3. Entrar na pasta do projeto\n",
        "%cd sam-3d-objects"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli whoami"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6nIb5AQb3Ux",
        "outputId": "b7d48aed-bf2d-40ea-81b4-180baa4a65af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli whoami' is deprecated. Use 'hf auth whoami' instead.\u001b[0m\n",
            "leandroars\n",
            "\u001b[1morgs: \u001b[0m MakerBros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Garantir que a ferramenta de download está na versão certa\n",
        "!pip install \"huggingface-hub[cli]<1.0\"\n",
        "\n",
        "# 2. Criar a pasta onde o modelo vai ficar\n",
        "!mkdir -p checkpoints/hf\n",
        "\n",
        "print(\"--- ⏳ Iniciando o download do Modelo... aguarde... ---\")\n",
        "\n",
        "# 3. Baixar os arquivos do Facebook\n",
        "!export TAG=hf && \\\n",
        " huggingface-cli download \\\n",
        " --repo-type model \\\n",
        " --local-dir checkpoints/$TAG-download \\\n",
        " --max-workers 4 \\\n",
        " facebook/sam-3d-objects\n",
        "\n",
        "# 4. Organizar os arquivos na pasta correta\n",
        "!mv checkpoints/hf-download/checkpoints/* checkpoints/hf/\n",
        "!rm -rf checkpoints/hf-download\n",
        "\n",
        "print(\"--- ✅ Sucesso! Modelo baixado e pronto. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtN8aQD7ddHQ",
        "outputId": "a1d14e95-e8fe-4d32-8484-6b5339c5e242"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub<1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli]<1.0) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (1.2.0)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface-hub[cli]<1.0)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (3.0.52)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2025.11.12)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (0.2.14)\n",
            "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: pfzy, InquirerPy\n",
            "Successfully installed InquirerPy-0.3.4 pfzy-0.3.4\n",
            "--- ⏳ Iniciando o download do Modelo... aguarde... ---\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 28 files:   0% 0/28 [00:00<?, ?it/s]\n",
            "Downloading 'LICENSE' to 'checkpoints/hf-download/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.e58d758cc3d92e6d1a57b52f7e4d203d02a67e98.incomplete'\n",
            "Downloading 'README.md' to 'checkpoints/hf-download/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8b9ceecf92202d3b7f8d6c337b332e89753141e5.incomplete'\n",
            "LICENSE: 100% 8.20k/8.20k [00:00<00:00, 48.0MB/s]\n",
            "Download complete. Moving file to checkpoints/hf-download/LICENSE\n",
            "README.md: 100% 7.20k/7.20k [00:00<00:00, 23.9MB/s]\n",
            "Download complete. Moving file to checkpoints/hf-download/README.md\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 402, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 157, in run\n",
            "    print(self._download())  # Print path to downloaded files\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 191, in _download\n",
            "    return snapshot_download(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 332, in snapshot_download\n",
            "    thread_map(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
            "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "               ^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "    yield _result_or_cancel(fs.pop())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
            "    return fut.result(timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 306, in _inner_hf_hub_download\n",
            "    return hf_hub_download(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 987, in hf_hub_download\n",
            "    return _hf_hub_download_to_local_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1250, in _hf_hub_download_to_local_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1655, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1543, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1460, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 283, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 307, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 419, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-6926430e-6a9f0afc046f53924005331f;2603e32a-bc06-4fe2-9acf-0d9541f3cca2)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes.\n",
            "Access to model facebook/sam-3d-objects is restricted and you are not in the authorized list. Visit https://huggingface.co/facebook/sam-3d-objects to ask for access.\n",
            "mv: cannot stat 'checkpoints/hf-download/checkpoints/*': No such file or directory\n",
            "--- ✅ Sucesso! Modelo baixado e pronto. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# 1. FORÇAR a entrada na pasta correta\n",
        "%cd /content/sam-3d-objects\n",
        "\n",
        "# 2. Adicionar o caminho EXATO onde está o arquivo inference.py\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "\n",
        "# 3. Agora tentamos importar novamente\n",
        "from inference import Inference, load_image\n",
        "\n",
        "print(\"--- ⚙️ Carregando o modelo (pode levar 1 minuto)... ---\")\n",
        "tag = \"hf\"\n",
        "config_path = f\"checkpoints/{tag}/pipeline.yaml\"\n",
        "\n",
        "# Inicializa a IA\n",
        "inference = Inference(config_path, compile=False)\n",
        "print(\"--- 🚀 Modelo carregado e pronto! ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "5dXlKQ7AeN-6",
        "outputId": "9a16e1d0-a11a-44a9-f6fb-027ac23bdce0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/sam-3d-objects'\n",
            "/content\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'inference'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1281641669.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 3. Agora tentamos importar novamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- ⚙️ Carregando o modelo (pode levar 1 minuto)... ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inference'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. Verifica se a pasta sumiu e baixa de novo se precisar\n",
        "if not os.path.exists('/content/sam-3d-objects'):\n",
        "    print(\"⚠️ A pasta sumiu! O Colab deve ter reiniciado.\")\n",
        "    print(\"--- Baixando o código novamente... ---\")\n",
        "    %cd /content/\n",
        "    !git clone https://github.com/facebookresearch/sam-3d-objects.git\n",
        "else:\n",
        "    print(\"✅ A pasta ainda está aqui.\")\n",
        "\n",
        "# 2. Entra na pasta correta\n",
        "%cd /content/sam-3d-objects\n",
        "\n",
        "# 3. Adiciona o caminho ao sistema (para o Python achar o arquivo)\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "\n",
        "# 4. Tenta importar novamente\n",
        "try:\n",
        "    from inference import Inference, load_image\n",
        "    print(\"\\n🎉 Sucesso! O módulo 'inference' foi encontrado.\")\n",
        "except ImportError:\n",
        "    print(\"\\n❌ Ainda deu erro. Se isso acontecer, você precisa subir lá no topo e rodar as células de INSTALAÇÃO (!pip install...) novamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4s_dfQ1fTZb",
        "outputId": "fc6b4dd6-c6a1-4d57-cd1d-2d7ac479a607"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ A pasta sumiu! O Colab deve ter reiniciado.\n",
            "--- Baixando o código novamente... ---\n",
            "/content\n",
            "Cloning into 'sam-3d-objects'...\n",
            "remote: Enumerating objects: 1101, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 1101 (delta 93), reused 82 (delta 82), pack-reused 985 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1101/1101), 266.74 MiB | 24.13 MiB/s, done.\n",
            "Resolving deltas: 100% (401/401), done.\n",
            "Updating files: 100% (415/415), done.\n",
            "/content/sam-3d-objects\n",
            "\n",
            "❌ Ainda deu erro. Se isso acontecer, você precisa subir lá no topo e rodar as células de INSTALAÇÃO (!pip install...) novamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrar na pasta certa (garantia)\n",
        "%cd /content/sam-3d-objects\n",
        "\n",
        "print(\"--- 🔄 Reinstalando dependências (Pode demorar um pouco)... ---\")\n",
        "!pip install -e \".[dev]\"\n",
        "!pip install -e \".[p3d]\"\n",
        "!pip install -e \".[inference]\"\n",
        "!pip install rembg\n",
        "\n",
        "print(\"--- 🔧 Aplicando correção do sistema ---\")\n",
        "!chmod +x patching/hydra\n",
        "!./patching/hydra\n",
        "\n",
        "print(\"✅ Instalação concluída!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkl8UST7fvaw",
        "outputId": "07deb26d-145b-46b3-d889-557bb4746280"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sam-3d-objects\n",
            "--- 🔄 Reinstalando dependências (Pode demorar um pouco)... ---\n",
            "Obtaining file:///content/sam-3d-objects\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting moge@ git+https://github.com/microsoft/MoGe.git@a8c37341bc0325ca99b9d57981cc3bb2bd3e255b (from sam3d_objects==0.0.1)\n",
            "  Cloning https://github.com/microsoft/MoGe.git (to revision a8c37341bc0325ca99b9d57981cc3bb2bd3e255b) to /tmp/pip-install-xt80iz_v/moge_6dc0a244373142c091a37497021fcd4b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/MoGe.git /tmp/pip-install-xt80iz_v/moge_6dc0a244373142c091a37497021fcd4b\n",
            "  Running command git rev-parse -q --verify 'sha^a8c37341bc0325ca99b9d57981cc3bb2bd3e255b'\n",
            "  Running command git fetch -q https://github.com/microsoft/MoGe.git a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Running command git checkout -q a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Resolved https://github.com/microsoft/MoGe.git to commit a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor==0.8.1 (from sam3d_objects==0.0.1)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting async-timeout==4.0.3 (from sam3d_objects==0.0.1)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting auto-gptq==0.7.1 (from sam3d_objects==0.0.1)\n",
            "  Downloading auto_gptq-0.7.1.tar.gz (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.1/126.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (from https://pypi.org/simple/auto-gptq/) (requires-python:>=3.8.0)\u001b[0m: \u001b[33mRequested auto-gptq==0.7.1 from https://files.pythonhosted.org/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (from sam3d_objects==0.0.1) has inconsistent version: expected '0.7.1', but metadata has '0.7.1+cu1251'\u001b[0m\n",
            "INFO: pip is looking at multiple versions of sam3d-objects to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement auto-gptq==0.7.1 (from sam3d-objects) (from versions: 0.0.4, 0.0.5, 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 0.5.0, 0.5.1, 0.6.0, 0.7.0, 0.7.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for auto-gptq==0.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/sam-3d-objects\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting moge@ git+https://github.com/microsoft/MoGe.git@a8c37341bc0325ca99b9d57981cc3bb2bd3e255b (from sam3d_objects==0.0.1)\n",
            "  Cloning https://github.com/microsoft/MoGe.git (to revision a8c37341bc0325ca99b9d57981cc3bb2bd3e255b) to /tmp/pip-install-o4fbh91d/moge_4257eba715a54ea6a0162a5f39eac53a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/MoGe.git /tmp/pip-install-o4fbh91d/moge_4257eba715a54ea6a0162a5f39eac53a\n",
            "  Running command git rev-parse -q --verify 'sha^a8c37341bc0325ca99b9d57981cc3bb2bd3e255b'\n",
            "  Running command git fetch -q https://github.com/microsoft/MoGe.git a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Running command git checkout -q a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Resolved https://github.com/microsoft/MoGe.git to commit a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor==0.8.1 (from sam3d_objects==0.0.1)\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting async-timeout==4.0.3 (from sam3d_objects==0.0.1)\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting auto-gptq==0.7.1 (from sam3d_objects==0.0.1)\n",
            "  Using cached auto_gptq-0.7.1.tar.gz (126 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (from https://pypi.org/simple/auto-gptq/) (requires-python:>=3.8.0)\u001b[0m: \u001b[33mRequested auto-gptq==0.7.1 from https://files.pythonhosted.org/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (from sam3d_objects==0.0.1) has inconsistent version: expected '0.7.1', but metadata has '0.7.1+cu1251'\u001b[0m\n",
            "INFO: pip is looking at multiple versions of sam3d-objects to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement auto-gptq==0.7.1 (from sam3d-objects) (from versions: 0.0.4, 0.0.5, 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 0.5.0, 0.5.1, 0.6.0, 0.7.0, 0.7.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for auto-gptq==0.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/sam-3d-objects\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting moge@ git+https://github.com/microsoft/MoGe.git@a8c37341bc0325ca99b9d57981cc3bb2bd3e255b (from sam3d_objects==0.0.1)\n",
            "  Cloning https://github.com/microsoft/MoGe.git (to revision a8c37341bc0325ca99b9d57981cc3bb2bd3e255b) to /tmp/pip-install-7w06z2du/moge_b9af3eefead949289e35ca0272e82afc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/MoGe.git /tmp/pip-install-7w06z2du/moge_b9af3eefead949289e35ca0272e82afc\n",
            "  Running command git rev-parse -q --verify 'sha^a8c37341bc0325ca99b9d57981cc3bb2bd3e255b'\n",
            "  Running command git fetch -q https://github.com/microsoft/MoGe.git a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Running command git checkout -q a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Resolved https://github.com/microsoft/MoGe.git to commit a8c37341bc0325ca99b9d57981cc3bb2bd3e255b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor==0.8.1 (from sam3d_objects==0.0.1)\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting async-timeout==4.0.3 (from sam3d_objects==0.0.1)\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting auto-gptq==0.7.1 (from sam3d_objects==0.0.1)\n",
            "  Using cached auto_gptq-0.7.1.tar.gz (126 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (from https://pypi.org/simple/auto-gptq/) (requires-python:>=3.8.0)\u001b[0m: \u001b[33mRequested auto-gptq==0.7.1 from https://files.pythonhosted.org/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (from sam3d_objects==0.0.1) has inconsistent version: expected '0.7.1', but metadata has '0.7.1+cu1251'\u001b[0m\n",
            "INFO: pip is looking at multiple versions of sam3d-objects to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement auto-gptq==0.7.1 (from sam3d-objects) (from versions: 0.0.4, 0.0.5, 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 0.5.0, 0.5.1, 0.6.0, 0.7.0, 0.7.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for auto-gptq==0.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting rembg\n",
            "  Downloading rembg-2.0.68-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from rembg) (4.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rembg) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from rembg) (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from rembg) (11.3.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.12/dist-packages (from rembg) (1.8.2)\n",
            "Collecting pymatting (from rembg)\n",
            "  Downloading pymatting-1.1.14-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from rembg) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from rembg) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from rembg) (4.67.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (0.29.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch->rembg) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pooch->rembg) (25.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch->rembg) (2.32.4)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.12/dist-packages (from pymatting->rembg) (0.60.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (0.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.43.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema->rembg) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (2025.11.12)\n",
            "Downloading rembg-2.0.68-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymatting-1.1.14-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymatting, rembg\n",
            "Successfully installed pymatting-1.1.14 rembg-2.0.68\n",
            "--- 🔧 Aplicando correção do sistema ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sam-3d-objects/./patching/hydra\", line 4, in <module>\n",
            "    import hydra\n",
            "ModuleNotFoundError: No module named 'hydra'\n",
            "✅ Instalação concluída!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar o Hydra manualmente (forçar a instalação)\n",
        "!pip install hydra-core --upgrade\n",
        "\n",
        "# 2. Agora sim, aplicar a correção (o patch)\n",
        "print(\"--- Tentando aplicar o patch novamente... ---\")\n",
        "!chmod +x patching/hydra\n",
        "!./patching/hydra\n",
        "\n",
        "print(\"✅ Agora deve ter funcionado!\")"
      ],
      "metadata": {
        "id": "wYpHMEhpiKKg",
        "outputId": "48a35050-e2c6-47f0-a55d-e7862b49ac80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.3)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hydra-core\n",
            "Successfully installed hydra-core-1.3.2\n",
            "--- Tentando aplicar o patch novamente... ---\n",
            "✅ Agora deve ter funcionado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar o Hydra manualmente (forçar a instalação)\n",
        "!pip install hydra-core --upgrade\n",
        "\n",
        "# 2. Agora sim, aplicar a correção (o patch)\n",
        "print(\"--- Tentando aplicar o patch novamente... ---\")\n",
        "!chmod +x patching/hydra\n",
        "!./patching/hydra\n",
        "\n",
        "print(\"✅ Agora deve ter funcionado!\")"
      ],
      "metadata": {
        "id": "uVVB4Vj6jAV8",
        "outputId": "7a75c45f-c625-4758-e72a-b58209751fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.3)\n",
            "--- Tentando aplicar o patch novamente... ---\n",
            "✅ Agora deve ter funcionado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "931a6e42b8fa4e2da219fd6b21ee239f",
            "504e953d0e894f6c8d32d9922fddc35b",
            "23d16104aa7d42c3a160b40e1280a40b",
            "7cc09649b5714ff9b91920bbcd516ef1",
            "74e32b5be94b42eb93dec65f46b3f223",
            "26f52afe82bb49e9b0cabb34b4b82b40",
            "df5a52d5b2d94191af89f9473b457bd3",
            "adfaabef2108452a86cc41ddb1a99ca4",
            "fa0c97d8e3604fc8a7bb0617a9b51a2f",
            "3b968a37ee214a778fb3e6163217e71b",
            "42eda2525ba04635b0f07e3d5cac4ef6",
            "b4c41b70f95a463bbb92a0c4166bf3f9",
            "96134acd1a3440b2b0036e3f1f5937df",
            "88f88e2458d14dfd85c7d6b37c48f3a9",
            "9d352c6094de4f379f5dec36b1c4d558",
            "ad3141501e654a0da477ffa807e1177f",
            "962928cba68d4b7f900761b26c28b87f",
            "e4bbb9443ae34cfe92ea18a733060aaf",
            "df33fbc34a434dd2850060412ea47619",
            "05658a550ad74430911194c2fce5e014"
          ]
        },
        "id": "Q41kJ6L7cPC2",
        "outputId": "f926387b-6a33-4d9a-92c8-2da042116dc6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "931a6e42b8fa4e2da219fd6b21ee239f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recriar a pasta e baixar o modelo\n",
        "!mkdir -p checkpoints/hf\n",
        "!pip install \"huggingface-hub[cli]<1.0\"\n",
        "\n",
        "print(\"--- ⬇️ Baixando o modelo... (Aguarde terminar) ---\")\n",
        "!export TAG=hf && \\\n",
        " huggingface-cli download \\\n",
        " --repo-type model \\\n",
        " --local-dir checkpoints/$TAG-download \\\n",
        " --max-workers 4 \\\n",
        " facebook/sam-3d-objects\n",
        "\n",
        "!mv checkpoints/hf-download/checkpoints/* checkpoints/hf/\n",
        "!rm -rf checkpoints/hf-download\n",
        "\n",
        "print(\"✅ Modelo baixado com sucesso!\")"
      ],
      "metadata": {
        "id": "eVaKtm3Hjd5h",
        "outputId": "941c78c6-3990-4697-9894-1cf5a9ba4ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub<1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli]<1.0) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (1.2.0)\n",
            "Requirement already satisfied: InquirerPy==0.3.4 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli]<1.0) (0.3.4)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (3.0.52)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2025.11.12)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (0.2.14)\n",
            "--- ⬇️ Baixando o modelo... (Aguarde terminar) ---\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 28 files:   0% 0/28 [00:00<?, ?it/s]Still waiting to acquire lock on checkpoints/hf-download/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
            "Fetching 28 files:   0% 0/28 [00:00<?, ?it/s]\n",
            "Downloading 'README.md' to 'checkpoints/hf-download/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8b9ceecf92202d3b7f8d6c337b332e89753141e5.incomplete'\n",
            "Downloading 'LICENSE' to 'checkpoints/hf-download/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.e58d758cc3d92e6d1a57b52f7e4d203d02a67e98.incomplete'\n",
            "README.md: 100% 7.20k/7.20k [00:00<00:00, 43.5MB/s]\n",
            "Download complete. Moving file to checkpoints/hf-download/README.md\n",
            "LICENSE: 100% 8.20k/8.20k [00:00<00:00, 54.5MB/s]\n",
            "Download complete. Moving file to checkpoints/hf-download/LICENSE\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 402, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 157, in run\n",
            "    print(self._download())  # Print path to downloaded files\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 191, in _download\n",
            "    return snapshot_download(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 332, in snapshot_download\n",
            "    thread_map(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
            "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "               ^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "    yield _result_or_cancel(fs.pop())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
            "    return fut.result(timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 306, in _inner_hf_hub_download\n",
            "    return hf_hub_download(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 987, in hf_hub_download\n",
            "    return _hf_hub_download_to_local_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1250, in _hf_hub_download_to_local_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1655, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1543, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1460, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 283, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 307, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 419, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-69264935-2ab5acbd05d323f1136e3aac;5e15ea24-5c6c-4666-839c-36a1713c6033)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes.\n",
            "Access to model facebook/sam-3d-objects is restricted and you are not in the authorized list. Visit https://huggingface.co/facebook/sam-3d-objects to ask for access.\n",
            "mv: cannot stat 'checkpoints/hf-download/checkpoints/*': No such file or directory\n",
            "✅ Modelo baixado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "# Configurar caminhos\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "%cd /content/sam-3d-objects\n",
        "from inference import Inference, load_image\n",
        "\n",
        "print(\"--- ⚙️ Carregando a IA... ---\")\n",
        "tag = \"hf\"\n",
        "config_path = f\"checkpoints/{tag}/pipeline.yaml\"\n",
        "inference = Inference(config_path, compile=False)\n",
        "\n",
        "# 1. Upload da imagem\n",
        "print(\"\\n👇 ENVIE SUA FOTO AGORA:\")\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "# 2. Processar\n",
        "image_pil = Image.open(filename).convert(\"RGB\")\n",
        "print(\"--- ✂️ Criando máscara... ---\")\n",
        "mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "# 3. Gerar 3D\n",
        "print(\"--- 🎲 Criando objeto 3D... ---\")\n",
        "output = inference(image_pil, mask_pil, seed=42)\n",
        "output[\"gs\"].save_ply(\"resultado_3d.ply\")\n",
        "\n",
        "print(\"\\n✅ PRONTO! Seu arquivo 'resultado_3d.ply' está na pasta à esquerda.\")"
      ],
      "metadata": {
        "id": "XV_vArVkjo9U",
        "outputId": "671217cb-8134-4637-9840-1f7400a7fbe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'onnxruntime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1522773573.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrembg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Configurar caminhos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rembg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_version\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msession_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnew_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rembg/bg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m from cv2 import (\n\u001b[1;32m      9\u001b[0m     \u001b[0mBORDER_DEFAULT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Correção rápida: Instalar a peça que falta\n",
        "print(\"--- 🔧 Instalando onnxruntime... ---\")\n",
        "!pip install onnxruntime onnxruntime-gpu rembg\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "# Configurar caminhos\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "%cd /content/sam-3d-objects\n",
        "from inference import Inference, load_image\n",
        "\n",
        "# 2. Carregar a IA\n",
        "print(\"--- ⚙️ Carregando a IA... ---\")\n",
        "tag = \"hf\"\n",
        "config_path = f\"checkpoints/{tag}/pipeline.yaml\"\n",
        "inference = Inference(config_path, compile=False)\n",
        "\n",
        "# 3. Upload da imagem\n",
        "print(\"\\n👇 ENVIE SUA FOTO AGORA:\")\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "# 4. Processar\n",
        "image_pil = Image.open(filename).convert(\"RGB\")\n",
        "print(\"--- ✂️ Criando máscara... ---\")\n",
        "mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "# Mostrar a máscara para você ver se ficou boa\n",
        "plt.imshow(mask_pil, cmap='gray')\n",
        "plt.title(\"Máscara gerada\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 5. Gerar 3D\n",
        "print(\"--- 🎲 Criando objeto 3D... (Isso leva uns 60 segundos) ---\")\n",
        "output = inference(image_pil, mask_pil, seed=42)\n",
        "output[\"gs\"].save_ply(\"resultado_3d.ply\")\n",
        "\n",
        "print(\"\\n✅ PRONTO! Seu arquivo 'resultado_3d.ply' está na pasta à esquerda.\")"
      ],
      "metadata": {
        "id": "gr03N5isk_ip",
        "outputId": "34db075c-bc37-4d26-b4ca-8cf9165c9e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 🔧 Instalando onnxruntime... ---\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: rembg in /usr/local/lib/python3.12/dist-packages (2.0.68)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from rembg) (4.25.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from rembg) (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from rembg) (11.3.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.12/dist-packages (from rembg) (1.8.2)\n",
            "Requirement already satisfied: pymatting in /usr/local/lib/python3.12/dist-packages (from rembg) (1.1.14)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from rembg) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from rembg) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from rembg) (4.67.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->rembg) (0.29.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch->rembg) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch->rembg) (2.32.4)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.12/dist-packages (from pymatting->rembg) (0.60.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->rembg) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.43.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema->rembg) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch->rembg) (2025.11.12)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (300.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2 onnxruntime-gpu-1.23.2\n",
            "/content/sam-3d-objects\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'inference'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3591729970.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sam-3d-objects/notebook\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/sam-3d-objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 2. Carregar a IA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inference'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "# 1. Configurar onde o Python deve buscar os arquivos\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "%cd /content/sam-3d-objects\n",
        "from inference import Inference, load_image\n",
        "\n",
        "# 2. Carregar o cérebro da IA (Modelos)\n",
        "print(\"--- ⚙️ Carregando o modelo SAM 3D... ---\")\n",
        "tag = \"hf\"\n",
        "config_path = f\"checkpoints/{tag}/pipeline.yaml\"\n",
        "inference = Inference(config_path, compile=False)\n",
        "\n",
        "# 3. Pedir a sua foto\n",
        "print(\"\\n👇 CLIQUE NO BOTÃO ABAIXO PARA ENVIAR SUA FOTO:\")\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "# 4. Preparar a imagem (remover fundo automaticamente)\n",
        "print(\"--- ✂️ Criando máscara do objeto... ---\")\n",
        "image_pil = Image.open(filename).convert(\"RGB\")\n",
        "mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "# Mostrar o que será processado\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,2,1); plt.imshow(image_pil); plt.title(\"Original\")\n",
        "plt.subplot(1,2,2); plt.imshow(mask_pil, cmap='gray'); plt.title(\"Máscara\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 5. Gerar o arquivo 3D\n",
        "print(\"--- 🎲 Criando o 3D... (Aguarde ~1 minuto) ---\")\n",
        "output = inference(image_pil, mask_pil, seed=42)\n",
        "\n",
        "# Salvar\n",
        "output_name = \"meu_modelo_3d.ply\"\n",
        "output[\"gs\"].save_ply(output_name)\n",
        "\n",
        "print(f\"\\n✅ SUCESSO! O arquivo '{output_name}' foi salvo.\")\n",
        "print(\"👉 Procure na pasta à esquerda (ícone de pasta) e faça o download!\")"
      ],
      "metadata": {
        "id": "UZCAacW2lwr6",
        "outputId": "6d6a3d9e-b605-41d2-aa55-e3812bdaf66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sam-3d-objects\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'inference'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-611480509.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sam-3d-objects/notebook\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/sam-3d-objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 2. Carregar o cérebro da IA (Modelos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inference'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import torch\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "print(\"--- 🕵️‍♂️ Iniciando diagnóstico e correção de pastas... ---\")\n",
        "\n",
        "# 1. Verificar se a pasta do projeto existe. Se não, baixa de novo.\n",
        "if not os.path.exists(\"/content/sam-3d-objects\"):\n",
        "    print(\"⚠️ A pasta do projeto sumiu. Baixando novamente...\")\n",
        "    !git clone https://github.com/facebookresearch/sam-3d-objects.git\n",
        "else:\n",
        "    print(\"✅ Pasta do projeto encontrada.\")\n",
        "\n",
        "# 2. TRUQUE: Copiar o arquivo 'inference.py' para a raiz para facilitar\n",
        "source_file = \"/content/sam-3d-objects/notebook/inference.py\"\n",
        "dest_file = \"/content/inference.py\"\n",
        "\n",
        "if os.path.exists(source_file):\n",
        "    shutil.copy(source_file, dest_file)\n",
        "    print(\"✅ Arquivo 'inference.py' movido para o local correto.\")\n",
        "else:\n",
        "    # Se o arquivo não existe, algo grave aconteceu com o download\n",
        "    print(\"❌ ERRO: O arquivo inference.py não foi encontrado. O download do Github falhou.\")\n",
        "    # Tenta baixar apenas o arquivo necessário\n",
        "    !wget https://raw.githubusercontent.com/facebookresearch/sam-3d-objects/main/notebook/inference.py -O /content/inference.py\n",
        "\n",
        "# 3. Importar (agora vai funcionar porque o arquivo está ao lado)\n",
        "sys.path.append(\"/content\")\n",
        "try:\n",
        "    from inference import Inference, load_image\n",
        "    print(\"🎉 Sucesso! O módulo 'inference' foi carregado.\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Ainda deu erro no import: {e}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# CÓDIGO DE GERAÇÃO 3D\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 4. Carregar a IA\n",
        "print(\"\\n--- ⚙️ Carregando o modelo SAM 3D... ---\")\n",
        "# Caminho absoluto para evitar erros\n",
        "config_path = \"/content/sam-3d-objects/checkpoints/hf/pipeline.yaml\"\n",
        "\n",
        "if not os.path.exists(config_path):\n",
        "    print(f\"❌ Erro: Não achei o arquivo de configuração em: {config_path}\")\n",
        "    print(\"Você baixou o modelo? (Passo do Login e Download)\")\n",
        "else:\n",
        "    inference = Inference(config_path, compile=False)\n",
        "\n",
        "    # 5. Upload da imagem\n",
        "    print(\"\\n👇 CLIQUE NO BOTÃO ABAIXO PARA ENVIAR SUA FOTO:\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"Nenhuma imagem enviada.\")\n",
        "    else:\n",
        "        filename = next(iter(uploaded))\n",
        "\n",
        "        # 6. Processar\n",
        "        print(\"--- ✂️ Criando máscara do objeto... ---\")\n",
        "        image_pil = Image.open(filename).convert(\"RGB\")\n",
        "        mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "        # Mostrar\n",
        "        plt.figure(figsize=(8,4))\n",
        "        plt.subplot(1,2,1); plt.imshow(image_pil); plt.title(\"Original\")\n",
        "        plt.subplot(1,2,2); plt.imshow(mask_pil, cmap='gray'); plt.title(\"Máscara\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # 7. Gerar 3D\n",
        "        print(\"--- 🎲 Criando o 3D... (Aguarde ~1 minuto) ---\")\n",
        "        output = inference(image_pil, mask_pil, seed=42)\n",
        "\n",
        "        output_name = \"meu_modelo_3d.ply\"\n",
        "        output[\"gs\"].save_ply(output_name)\n",
        "\n",
        "        print(f\"\\n✅ SUCESSO FINAL! O arquivo '{output_name}' foi salvo na pasta à esquerda.\")"
      ],
      "metadata": {
        "id": "K3eJjxMamePK",
        "outputId": "f809bc13-ef40-4327-fdba-c411c76c5bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 🕵️‍♂️ Iniciando diagnóstico e correção de pastas... ---\n",
            "✅ Pasta do projeto encontrada.\n",
            "✅ Arquivo 'inference.py' movido para o local correto.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'CONDA_PREFIX'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4153216864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🎉 Sucesso! O módulo 'inference' foi carregado.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# not ideal to put that here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_HOME\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CONDA_PREFIX\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LIDRA_SKIP_INIT\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CONDA_PREFIX'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import torch\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "print(\"--- 🕵️‍♂️ Iniciando diagnóstico e correção de pastas... ---\")\n",
        "\n",
        "# 1. Verificar se a pasta do projeto existe. Se não, baixa de novo.\n",
        "if not os.path.exists(\"/content/sam-3d-objects\"):\n",
        "    print(\"⚠️ A pasta do projeto sumiu. Baixando novamente...\")\n",
        "    !git clone https://github.com/facebookresearch/sam-3d-objects.git\n",
        "else:\n",
        "    print(\"✅ Pasta do projeto encontrada.\")\n",
        "\n",
        "# 2. TRUQUE: Copiar o arquivo 'inference.py' para a raiz para facilitar\n",
        "source_file = \"/content/sam-3d-objects/notebook/inference.py\"\n",
        "dest_file = \"/content/inference.py\"\n",
        "\n",
        "if os.path.exists(source_file):\n",
        "    shutil.copy(source_file, dest_file)\n",
        "    print(\"✅ Arquivo 'inference.py' movido para o local correto.\")\n",
        "else:\n",
        "    # Se o arquivo não existe, algo grave aconteceu com o download\n",
        "    print(\"❌ ERRO: O arquivo inference.py não foi encontrado. O download do Github falhou.\")\n",
        "    # Tenta baixar apenas o arquivo necessário\n",
        "    !wget https://raw.githubusercontent.com/facebookresearch/sam-3d-objects/main/notebook/inference.py -O /content/inference.py\n",
        "\n",
        "# 3. Importar (agora vai funcionar porque o arquivo está ao lado)\n",
        "sys.path.append(\"/content\")\n",
        "try:\n",
        "    from inference import Inference, load_image\n",
        "    print(\"🎉 Sucesso! O módulo 'inference' foi carregado.\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Ainda deu erro no import: {e}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# CÓDIGO DE GERAÇÃO 3D\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 4. Carregar a IA\n",
        "print(\"\\n--- ⚙️ Carregando o modelo SAM 3D... ---\")\n",
        "# Caminho absoluto para evitar erros\n",
        "config_path = \"/content/sam-3d-objects/checkpoints/hf/pipeline.yaml\"\n",
        "\n",
        "if not os.path.exists(config_path):\n",
        "    print(f\"❌ Erro: Não achei o arquivo de configuração em: {config_path}\")\n",
        "    print(\"Você baixou o modelo? (Passo do Login e Download)\")\n",
        "else:\n",
        "    inference = Inference(config_path, compile=False)\n",
        "\n",
        "    # 5. Upload da imagem\n",
        "    print(\"\\n👇 CLIQUE NO BOTÃO ABAIXO PARA ENVIAR SUA FOTO:\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"Nenhuma imagem enviada.\")\n",
        "    else:\n",
        "        filename = next(iter(uploaded))\n",
        "\n",
        "        # 6. Processar\n",
        "        print(\"--- ✂️ Criando máscara do objeto... ---\")\n",
        "        image_pil = Image.open(filename).convert(\"RGB\")\n",
        "        mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "        # Mostrar\n",
        "        plt.figure(figsize=(8,4))\n",
        "        plt.subplot(1,2,1); plt.imshow(image_pil); plt.title(\"Original\")\n",
        "        plt.subplot(1,2,2); plt.imshow(mask_pil, cmap='gray'); plt.title(\"Máscara\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # 7. Gerar 3D\n",
        "        print(\"--- 🎲 Criando o 3D... (Aguarde ~1 minuto) ---\")\n",
        "        output = inference(image_pil, mask_pil, seed=42)\n",
        "\n",
        "        output_name = \"meu_modelo_3d.ply\"\n",
        "        output[\"gs\"].save_ply(output_name)\n",
        "\n",
        "        print(f\"\\n✅ SUCESSO FINAL! O arquivo '{output_name}' foi salvo na pasta à esquerda.\")"
      ],
      "metadata": {
        "id": "3ZXgoTZ5miw7",
        "outputId": "4723bf6b-be5c-423e-9313-36aecb05d46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 🕵️‍♂️ Iniciando diagnóstico e correção de pastas... ---\n",
            "✅ Pasta do projeto encontrada.\n",
            "✅ Arquivo 'inference.py' movido para o local correto.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'CONDA_PREFIX'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4153216864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🎉 Sucesso! O módulo 'inference' foi carregado.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# not ideal to put that here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_HOME\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CONDA_PREFIX\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LIDRA_SKIP_INIT\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CONDA_PREFIX'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import torch\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "# --- CORREÇÃO DO ERRO ---\n",
        "# Enganar o código dizendo que o Conda está na pasta padrão do Colab\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'\n",
        "# ------------------------\n",
        "\n",
        "print(\"--- 🕵️‍♂️ Iniciando... ---\")\n",
        "\n",
        "# 1. Verificar pasta do projeto\n",
        "if not os.path.exists(\"/content/sam-3d-objects\"):\n",
        "    print(\"⚠️ Pasta sumiu. Baixando de novo...\")\n",
        "    !git clone https://github.com/facebookresearch/sam-3d-objects.git\n",
        "\n",
        "# 2. Copiar arquivo inference.py para a raiz (evita erro de import)\n",
        "source_file = \"/content/sam-3d-objects/notebook/inference.py\"\n",
        "dest_file = \"/content/inference.py\"\n",
        "if os.path.exists(source_file):\n",
        "    shutil.copy(source_file, dest_file)\n",
        "\n",
        "# 3. Importar\n",
        "sys.path.append(\"/content\")\n",
        "try:\n",
        "    from inference import Inference, load_image\n",
        "    print(\"✅ Sucesso! Módulo carregado.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erro ainda: {e}\")\n",
        "\n",
        "# 4. Carregar a IA\n",
        "print(\"\\n--- ⚙️ Carregando o modelo SAM 3D... ---\")\n",
        "config_path = \"/content/sam-3d-objects/checkpoints/hf/pipeline.yaml\"\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    inference = Inference(config_path, compile=False)\n",
        "\n",
        "    # 5. Upload da imagem\n",
        "    print(\"\\n👇 CLIQUE NO BOTÃO ABAIXO PARA ENVIAR SUA FOTO:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = next(iter(uploaded))\n",
        "\n",
        "        # 6. Processar Máscara\n",
        "        print(\"--- ✂️ Criando máscara... ---\")\n",
        "        image_pil = Image.open(filename).convert(\"RGB\")\n",
        "        mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "        # Mostrar preview\n",
        "        plt.figure(figsize=(8,4))\n",
        "        plt.subplot(1,2,1); plt.imshow(image_pil); plt.title(\"Original\")\n",
        "        plt.subplot(1,2,2); plt.imshow(mask_pil, cmap='gray'); plt.title(\"Máscara\")\n",
        "        plt.axis('off'); plt.show()\n",
        "\n",
        "        # 7. Gerar 3D\n",
        "        print(\"--- 🎲 Criando o 3D... (Aguarde ~1 minuto) ---\")\n",
        "        output = inference(image_pil, mask_pil, seed=42)\n",
        "\n",
        "        output_name = \"meu_modelo_3d.ply\"\n",
        "        output[\"gs\"].save_ply(output_name)\n",
        "\n",
        "        print(f\"\\n✅ SUCESSO! Baixe o arquivo '{output_name}' na pasta à esquerda.\")\n",
        "    else:\n",
        "        print(\"Nenhuma imagem selecionada.\")\n",
        "else:\n",
        "    print(\"❌ Erro: O arquivo pipeline.yaml não foi encontrado. O download do modelo (passo anterior) falhou?\")"
      ],
      "metadata": {
        "id": "nLb_yFC_mu5U",
        "outputId": "51cc02ad-d520-4032-dc8a-c43afee66a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 🕵️‍♂️ Iniciando... ---\n",
            "❌ Erro ainda: No module named 'utils3d'\n",
            "\n",
            "--- ⚙️ Carregando o modelo SAM 3D... ---\n",
            "❌ Erro: O arquivo pipeline.yaml não foi encontrado. O download do modelo (passo anterior) falhou?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula de Reparo e Download\n",
        "import os\n",
        "\n",
        "!mkdir -p checkpoints/hf\n",
        "!pip install \"huggingface-hub[cli]<1.0\"\n",
        "\n",
        "print(\"--- ⬇️ BAIXANDO O MODELO (Não feche a aba!) ---\")\n",
        "# Baixa apenas se não existir\n",
        "if not os.path.exists(\"checkpoints/hf/pipeline.yaml\"):\n",
        "    !export TAG=hf && \\\n",
        "     huggingface-cli download \\\n",
        "     --repo-type model \\\n",
        "     --local-dir checkpoints/$TAG-download \\\n",
        "     --max-workers 4 \\\n",
        "     facebook/sam-3d-objects\n",
        "\n",
        "    !mv checkpoints/hf-download/checkpoints/* checkpoints/hf/\n",
        "    !rm -rf checkpoints/hf-download\n",
        "    print(\"✅ Download Concluído!\")\n",
        "else:\n",
        "    print(\"✅ O modelo já está aí! Pode pular para a próxima etapa.\")"
      ],
      "metadata": {
        "id": "OhTFWKzZnU6W",
        "outputId": "f9e2164e-7273-4a34-ec76-9fabb2d0adf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub<1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli]<1.0) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0->huggingface-hub[cli]<1.0) (1.2.0)\n",
            "Requirement already satisfied: InquirerPy==0.3.4 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli]<1.0) (0.3.4)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (3.0.52)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0->huggingface-hub[cli]<1.0) (2025.11.12)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli]<1.0) (0.2.14)\n",
            "--- ⬇️ BAIXANDO O MODELO (Não feche a aba!) ---\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 28 files:   0% 0/28 [00:00<?, ?it/s]\n",
            "Downloading 'LICENSE' to 'checkpoints/hf-download/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.e58d758cc3d92e6d1a57b52f7e4d203d02a67e98.incomplete'\n",
            "Downloading 'README.md' to 'checkpoints/hf-download/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8b9ceecf92202d3b7f8d6c337b332e89753141e5.incomplete'\n",
            "LICENSE: 100% 8.20k/8.20k [00:00<00:00, 42.6MB/s]\n",
            "Download complete. Moving file to checkpoints/hf-download/LICENSE\n",
            "README.md: 100% 7.20k/7.20k [00:00<00:00, 48.7MB/s]\n",
            "Download complete. Moving file to checkpoints/hf-download/README.md\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 402, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 157, in run\n",
            "    print(self._download())  # Print path to downloaded files\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 191, in _download\n",
            "    return snapshot_download(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 332, in snapshot_download\n",
            "    thread_map(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
            "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "               ^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "    yield _result_or_cancel(fs.pop())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
            "    return fut.result(timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 306, in _inner_hf_hub_download\n",
            "    return hf_hub_download(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 987, in hf_hub_download\n",
            "    return _hf_hub_download_to_local_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1250, in _hf_hub_download_to_local_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1655, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1543, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1460, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 283, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 307, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 419, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-69264d2a-31b2f4a6336f93b648fce105;8596e79f-e28a-4e75-a4d1-6d625b150381)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes.\n",
            "Access to model facebook/sam-3d-objects is restricted and you are not in the authorized list. Visit https://huggingface.co/facebook/sam-3d-objects to ask for access.\n",
            "mv: cannot stat 'checkpoints/hf-download/checkpoints/*': No such file or directory\n",
            "✅ Download Concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "# --- CORREÇÃO DOS ERROS ---\n",
        "# 1. Define a variável que faltava (Conda)\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'\n",
        "\n",
        "# 2. Aponta para a pasta correta ONDE ESTÃO os arquivos (não movemos nada)\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "\n",
        "# 3. Entra na pasta raiz do projeto para o modelo achar os pesos\n",
        "%cd /content/sam-3d-objects\n",
        "\n",
        "# --------------------------\n",
        "\n",
        "try:\n",
        "    from inference import Inference, load_image\n",
        "    print(\"✅ Módulo Inference carregado corretamente!\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Erro crítico: {e}\")\n",
        "    print(\"Verifique se a pasta '/content/sam-3d-objects/notebook' existe na aba de arquivos.\")\n",
        "\n",
        "# Verificação final do modelo\n",
        "config_path = \"checkpoints/hf/pipeline.yaml\"\n",
        "if not os.path.exists(config_path):\n",
        "    print(\"\\n🚨 PARE TUDO! O arquivo pipeline.yaml ainda não existe.\")\n",
        "    print(\"Você precisa rodar a ETAPA 1 acima para baixar o modelo.\")\n",
        "else:\n",
        "    print(\"\\n--- ⚙️ Carregando a IA... ---\")\n",
        "    inference = Inference(config_path, compile=False)\n",
        "\n",
        "    print(\"\\n👇 ENVIE SUA FOTO AGORA:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = next(iter(uploaded))\n",
        "        image_pil = Image.open(filename).convert(\"RGB\")\n",
        "\n",
        "        print(\"--- ✂️ Processando imagem... ---\")\n",
        "        mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "        print(\"--- 🎲 Gerando 3D... ---\")\n",
        "        output = inference(image_pil, mask_pil, seed=42)\n",
        "\n",
        "        output[\"gs\"].save_ply(\"resultado_final.ply\")\n",
        "        print(\"\\n🏆 SUCESSO! Baixe 'resultado_final.ply' na pasta do projeto.\")\n",
        "    else:\n",
        "        print(\"Nenhuma imagem enviada.\")"
      ],
      "metadata": {
        "id": "8Eis69drndQa",
        "outputId": "9ea8d0c4-13c2-4322-d832-13ddd5af0219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sam-3d-objects\n",
            "❌ Erro crítico: No module named 'utils3d'\n",
            "Verifique se a pasta '/content/sam-3d-objects/notebook' existe na aba de arquivos.\n",
            "\n",
            "🚨 PARE TUDO! O arquivo pipeline.yaml ainda não existe.\n",
            "Você precisa rodar a ETAPA 1 acima para baixar o modelo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "print(\"--- 🧹 FAXINA: Removendo arquivos conflitantes... ---\")\n",
        "# 1. Apagar o arquivo que está confundindo o Python\n",
        "if os.path.exists(\"/content/inference.py\"):\n",
        "    os.remove(\"/content/inference.py\")\n",
        "    print(\"✅ Arquivo 'inference.py' antigo removido.\")\n",
        "\n",
        "# 2. Resetar caminhos do Python\n",
        "if \"/content\" in sys.path:\n",
        "    sys.path.remove(\"/content\")\n",
        "\n",
        "print(\"--- 🔍 Verificando Modelo... ---\")\n",
        "# 3. Garantir que o modelo existe (Download obrigatório)\n",
        "# Se o arquivo não estiver lá, ele baixa.\n",
        "config_path = \"/content/sam-3d-objects/checkpoints/hf/pipeline.yaml\"\n",
        "\n",
        "if not os.path.exists(config_path):\n",
        "    print(\"⚠️ O modelo não foi encontrado. Iniciando download (pode demorar 5 min)...\")\n",
        "    # Instalar CLI do HuggingFace\n",
        "    !pip install \"huggingface-hub[cli]<1.0\" > /dev/null\n",
        "\n",
        "    # Criar pastas\n",
        "    !mkdir -p /content/sam-3d-objects/checkpoints/hf\n",
        "\n",
        "    # Baixar\n",
        "    !export TAG=hf && \\\n",
        "     huggingface-cli download \\\n",
        "     --repo-type model \\\n",
        "     --local-dir /content/sam-3d-objects/checkpoints/$TAG-download \\\n",
        "     --max-workers 4 \\\n",
        "     facebook/sam-3d-objects\n",
        "\n",
        "    # Mover\n",
        "    !mv /content/sam-3d-objects/checkpoints/hf-download/checkpoints/* /content/sam-3d-objects/checkpoints/hf/\n",
        "    !rm -rf /content/sam-3d-objects/checkpoints/hf-download\n",
        "    print(\"✅ Download Concluído!\")\n",
        "else:\n",
        "    print(\"✅ O modelo já existe! Pulando download.\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# EXECUÇÃO DO SAM 3D\n",
        "# ---------------------------------------------------------\n",
        "print(\"--- 🚀 Iniciando SAM 3D... ---\")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "# Configurar ambiente\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "%cd /content/sam-3d-objects\n",
        "\n",
        "# Importar do local correto\n",
        "try:\n",
        "    # Forçar recarregamento para ignorar cache antigo\n",
        "    if 'inference' in sys.modules:\n",
        "        del sys.modules['inference']\n",
        "    from inference import Inference, load_image\n",
        "    print(\"✅ Sistema carregado corretamente.\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Erro fatal no import: {e}\")\n",
        "    print(\"Dica: Se o erro persistir, vá em 'Runtime' > 'Restart Session' e rode APENAS as instalações iniciais e este bloco.\")\n",
        "\n",
        "# Carregar IA\n",
        "inference = Inference(config_path, compile=False)\n",
        "\n",
        "# Upload e Geração\n",
        "print(\"\\n👇 ENVIE SUA FOTO AGORA:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = next(iter(uploaded))\n",
        "    image_pil = Image.open(filename).convert(\"RGB\")\n",
        "\n",
        "    print(\"--- ✂️ Removendo fundo... ---\")\n",
        "    mask_pil = remove(image_"
      ],
      "metadata": {
        "id": "_2fdayTlnpP5",
        "outputId": "805d0b1b-2974-4fa6-c63f-6096d5efbce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-3231668985.py, line 78)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3231668985.py\"\u001b[0;36m, line \u001b[0;32m78\u001b[0m\n\u001b[0;31m    mask_pil = remove(image_\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from rembg import remove\n",
        "\n",
        "# 1. Configurar ambiente e caminhos\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'\n",
        "sys.path.append(\"/content/sam-3d-objects/notebook\")\n",
        "os.chdir(\"/content/sam-3d-objects\")\n",
        "\n",
        "try:\n",
        "    # Remove importação antiga da memória para evitar conflitos\n",
        "    if 'inference' in sys.modules:\n",
        "        del sys.modules['inference']\n",
        "    from inference import Inference, load_image\n",
        "    print(\"✅ Sistema carregado!\")\n",
        "except ImportError:\n",
        "    print(\"⚠️ Atenção: Se der erro aqui, certifique-se que a pasta sam-3d-objects existe.\")\n",
        "\n",
        "# 2. Carregar a IA\n",
        "print(\"--- ⚙️ Carregando Cérebro da IA... ---\")\n",
        "config_path = \"/content/sam-3d-objects/checkpoints/hf/pipeline.yaml\"\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    inference = Inference(config_path, compile=False)\n",
        "\n",
        "    # 3. Upload e Geração\n",
        "    print(\"\\n👇 CLIQUE NO BOTÃO ABAIXO E ENVIE SUA FOTO:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = next(iter(uploaded))\n",
        "        image_pil = Image.open(filename).convert(\"RGB\")\n",
        "\n",
        "        print(\"--- ✂️ Removendo fundo da imagem... ---\")\n",
        "        # A LINHA QUE TINHA DADO ERRO AGORA ESTÁ COMPLETA ABAIXO:\n",
        "        mask_pil = remove(image_pil, only_mask=True).convert(\"L\").resize(image_pil.size)\n",
        "\n",
        "        # Mostra o que vai ser feito\n",
        "        plt.figure(figsize=(6,3))\n",
        "        plt.subplot(1,2,1); plt.imshow(image_pil); plt.title(\"Sua Foto\")\n",
        "        plt.subplot(1,2,2); plt.imshow(mask_pil, cmap='gray'); plt.title(\"Máscara Automática\")\n",
        "        plt.axis('off'); plt.show()\n",
        "\n",
        "        print(\"--- 🎲 Criando o 3D... (Aguarde ~1 minuto) ---\")\n",
        "        output = inference(image_pil, mask_pil, seed=42)\n",
        "\n",
        "        output[\"gs\"].save_ply(\"meu_3d_final.ply\")\n",
        "        print(\"\\n🏆 SUCESSO! O arquivo 'meu_3d_final.ply' apareceu na pasta à esquerda. Pode baixar!\")\n",
        "    else:\n",
        "        print(\"❌ Nenhuma imagem enviada.\")\n",
        "else:\n",
        "    print(\"❌ ERRO: O arquivo do modelo (pipeline.yaml) não foi encontrado.\")\n",
        "    print(\"Você precisa rodar o bloco de DOWNLOAD novamente (o passo anterior).\")"
      ],
      "metadata": {
        "id": "Qt4WJG36n2Yw",
        "outputId": "5eb9b3e6-e89e-4711-c6be-88e25ad027cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Atenção: Se der erro aqui, certifique-se que a pasta sam-3d-objects existe.\n",
            "--- ⚙️ Carregando Cérebro da IA... ---\n",
            "❌ ERRO: O arquivo do modelo (pipeline.yaml) não foi encontrado.\n",
            "Você precisa rodar o bloco de DOWNLOAD novamente (o passo anterior).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"--- ⬇️ INICIANDO DOWNLOAD DO MODELO (Isso é obrigatório) ---\")\n",
        "print(\"Aguarde... pode levar uns 5 a 10 minutos.\")\n",
        "\n",
        "# 1. Instalar ferramenta\n",
        "!pip install \"huggingface-hub[cli]<1.0\" > /dev/null\n",
        "\n",
        "# 2. Criar pastas certinhas\n",
        "!mkdir -p /content/sam-3d-objects/checkpoints/hf\n",
        "\n",
        "# 3. Baixar\n",
        "!export TAG=hf && \\\n",
        " huggingface-cli download \\\n",
        " --repo-type model \\\n",
        " --local-dir /content/sam-3d-objects/checkpoints/$TAG-download \\\n",
        " --max-workers 4 \\\n",
        " facebook/sam-3d-objects\n",
        "\n",
        "# 4. Mover para o lugar final\n",
        "!mv /content/sam-3d-objects/checkpoints/hf-download/checkpoints/* /content/sam-3d-objects/checkpoints/hf/\n",
        "!rm -rf /content/sam-3d-objects/checkpoints/hf-download\n",
        "\n",
        "# 5. Verificação final\n",
        "if os.path.exists(\"/content/sam-3d-objects/checkpoints/hf/pipeline.yaml\"):\n",
        "    print(\"\\n✅ SUCESSO! O arquivo 'pipeline.yaml' está no lugar certo.\")\n",
        "    print(\"👉 AGORA SIM: Pode rodar o código de gerar o 3D (Etapa 2).\")\n",
        "else:\n",
        "    print(\"\\n❌ ERRO: O download falhou. Tente rodar o comando 'login()' novamente antes de baixar.\")"
      ],
      "metadata": {
        "id": "smWAS1ZaoDRJ",
        "outputId": "e877f204-f824-4684-a815-fa0733a52462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ⬇️ INICIANDO DOWNLOAD DO MODELO (Isso é obrigatório) ---\n",
            "Aguarde... pode levar uns 5 a 10 minutos.\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 28 files:   0% 0/28 [00:00<?, ?it/s]\n",
            "Downloading 'LICENSE' to '/content/sam-3d-objects/checkpoints/hf-download/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.e58d758cc3d92e6d1a57b52f7e4d203d02a67e98.incomplete'\n",
            "Downloading 'README.md' to '/content/sam-3d-objects/checkpoints/hf-download/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8b9ceecf92202d3b7f8d6c337b332e89753141e5.incomplete'\n",
            "LICENSE: 100% 8.20k/8.20k [00:00<00:00, 50.3MB/s]\n",
            "Download complete. Moving file to /content/sam-3d-objects/checkpoints/hf-download/LICENSE\n",
            "README.md: 100% 7.20k/7.20k [00:00<00:00, 45.9MB/s]\n",
            "Download complete. Moving file to /content/sam-3d-objects/checkpoints/hf-download/README.md\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 402, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 157, in run\n",
            "    print(self._download())  # Print path to downloaded files\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 191, in _download\n",
            "    return snapshot_download(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 332, in snapshot_download\n",
            "    thread_map(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
            "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "               ^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "    yield _result_or_cancel(fs.pop())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
            "    return fut.result(timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 306, in _inner_hf_hub_download\n",
            "    return hf_hub_download(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 987, in hf_hub_download\n",
            "    return _hf_hub_download_to_local_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1250, in _hf_hub_download_to_local_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1655, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1543, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1460, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 283, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 307, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 419, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-69264de7-38261fcb4bad906f22dcd2c1;67b6e671-1e92-4c15-afb3-ed981ecf31f0)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes.\n",
            "Access to model facebook/sam-3d-objects is restricted and you are not in the authorized list. Visit https://huggingface.co/facebook/sam-3d-objects to ask for access.\n",
            "mv: cannot stat '/content/sam-3d-objects/checkpoints/hf-download/checkpoints/*': No such file or directory\n",
            "\n",
            "❌ ERRO: O download falhou. Tente rodar o comando 'login()' novamente antes de baixar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "# Vai pedir o token. Cole o token (começa com hf_) e dê Enter.\n",
        "login()"
      ],
      "metadata": {
        "id": "oO8rO_MjoQ0e",
        "outputId": "e5257a51-9bac-4ff3-d024-bfc330a26dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2ec28634284f4ee8bf7656d4147e4c0b",
            "4c7e99f63a1f4aa3b188a6275af0f59f",
            "a5c3338582554eba9bd804bde3276eda",
            "79db8f1530be4f06a35f2af908ca5041",
            "2324aa3b022540caa54d924e700a536b",
            "f5613da8560b4a6ab84e95cd6b12dd66",
            "cb55e92abf98428d9c507d882d86d315",
            "4c7963f5c4564a2cb4f26cfd47153264",
            "c346740c970c47c5a81e02f233844750",
            "ab724bd14f16449eb15e6871332c7359",
            "7f67494d579d43fc83eff7126e9290d8",
            "596bb8785dce4bb8af148731d60c08f1",
            "350fea18778f40289288315a96717624",
            "660b7103569643dfab5f63f88e229b8f",
            "eda8a3845bb94d4ab7e067303d5fd5c6",
            "4d758cee1b7e43a2a539a5aa9784cd51",
            "a52b68e1a2f0481ba0eb15220de0d674",
            "551097d9381d4d7abc7d0a0c5bc7bdc8",
            "93480f0fefa34fd3ba00e5ddcea892b3",
            "5eff9558fcac4a7a9f056e46c6fad38f"
          ]
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ec28634284f4ee8bf7656d4147e4c0b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Código de download do modelo\n",
        "!pip install \"huggingface-hub[cli]<1.0\" > /dev/null\n",
        "!mkdir -p /content/sam-3d-objects/checkpoints/hf\n",
        "\n",
        "print(\"--- ⬇️ TENTANDO BAIXAR DE NOVO... ---\")\n",
        "!export TAG=hf && \\\n",
        " huggingface-cli download \\\n",
        " --repo-type model \\\n",
        " --local-dir /content/sam-3d-objects/checkpoints/$TAG-download \\\n",
        " --max-workers 4 \\\n",
        " facebook/sam-3d-objects\n",
        "\n",
        "!mv /content/sam-3d-objects/checkpoints/hf-download/checkpoints/* /content/sam-3d-objects/checkpoints/hf/\n",
        "!rm -rf /content/sam-3d-objects/checkpoints/hf-download\n",
        "\n",
        "print(\"✅ Se não deu erro vermelho, funcionou!\")"
      ],
      "metadata": {
        "id": "2APsViJLoXDT",
        "outputId": "02a048c9-b594-4584-ba5d-fdf6e76f27ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ⬇️ TENTANDO BAIXAR DE NOVO... ---\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 28 files:   0% 0/28 [00:00<?, ?it/s]Downloading 'LICENSE' to '/content/sam-3d-objects/checkpoints/hf-download/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.e58d758cc3d92e6d1a57b52f7e4d203d02a67e98.incomplete'\n",
            "Fetching 28 files:   0% 0/28 [00:00<?, ?it/s]\n",
            "Downloading 'README.md' to '/content/sam-3d-objects/checkpoints/hf-download/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.8b9ceecf92202d3b7f8d6c337b332e89753141e5.incomplete'\n",
            "LICENSE: 100% 8.20k/8.20k [00:00<00:00, 40.2MB/s]\n",
            "Download complete. Moving file to /content/sam-3d-objects/checkpoints/hf-download/LICENSE\n",
            "README.md: 100% 7.20k/7.20k [00:00<00:00, 34.9MB/s]\n",
            "Download complete. Moving file to /content/sam-3d-objects/checkpoints/hf-download/README.md\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 402, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 157, in run\n",
            "    print(self._download())  # Print path to downloaded files\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py\", line 191, in _download\n",
            "    return snapshot_download(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 332, in snapshot_download\n",
            "    thread_map(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
            "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "               ^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "    yield _result_or_cancel(fs.pop())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
            "    return fut.result(timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\", line 306, in _inner_hf_hub_download\n",
            "    return hf_hub_download(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 987, in hf_hub_download\n",
            "    return _hf_hub_download_to_local_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1250, in _hf_hub_download_to_local_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1655, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1543, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1460, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 283, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 307, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 419, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-69264e39-495e6c5f5916b5511c13476d;38e364ee-4f29-4649-b686-c133fc89e72b)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/facebook/sam-3d-objects/resolve/a878e8e0f869d6db637cf2f096ff5ae5fac786b6/.gitattributes.\n",
            "Access to model facebook/sam-3d-objects is restricted and you are not in the authorized list. Visit https://huggingface.co/facebook/sam-3d-objects to ask for access.\n",
            "mv: cannot stat '/content/sam-3d-objects/checkpoints/hf-download/checkpoints/*': No such file or directory\n",
            "✅ Se não deu erro vermelho, funcionou!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e33eb1b3"
      },
      "source": [
        "print(\"--- Instalando dependências básicas (Dev) ---\")\n",
        "!pip install -e \".[dev]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02e9473b"
      },
      "source": [
        "print(\"--- Instalando PyTorch3D e Kaolin (Pode demorar alguns minutos) ---\")\n",
        "!pip install -e \".[p3d]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc32483f"
      },
      "source": [
        "print(\"--- Instalando dependências de Inferência ---\")\n",
        "!pip install -e \".[inference]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ea8e3a3"
      },
      "source": [
        "print(\"---\n",
        "--- Aplicando Patch ---\n",
        "---\")\n",
        "!chmod +x patching/hydra\n",
        "!./patching/hydra"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}